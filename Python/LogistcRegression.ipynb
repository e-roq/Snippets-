{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logisitc Regession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Data\n",
    "df = pd.read_csv('data.csv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X and Y\n",
    "X = df.drop(['y_var'], axis=1)\n",
    "y = df['y_var']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the following to encode cateogorical dependent variables:\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "oenc=OneHotEncoder(drop='first')\n",
    "multiple_enc=oenc.fit_transform(X[['Venue','Day','Time','Captain','Opposition']])# onehotencoding on  features\n",
    "multiple_enc=multiple_enc.toarray()\n",
    "\n",
    "#oenc.get_feature_names() use this method to get column names\n",
    "multiple_enc=pd.DataFrame(multiple_enc,columns=oenc.get_feature_names_out())\n",
    "multiple_enc.head()\n",
    "X = pd.concat([X[[\"PrevFandA\",\"WinPreviousTimePlayingSameTeam\",\"Rank\"]],multiple_enc],axis=1) # append to original dataframe\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Training and Test Data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "log_reg = sm.Logit(y_train, X_train).fit() # fit model\n",
    "\n",
    "print(log_reg.summary()) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test data\n",
    "y_pred_test = log_reg.predict(exog=X_test)\n",
    "# Convert predicted probabilities to binary class (0 or 1)\n",
    "y_pred_test = y_pred_test.apply(lambda x: 1 if x >= 0.5 else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get test accuaracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('Model accuracy score: {0:0.4f}'. format(accuracy_score(y_test, y_pred_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare the train-set and test-set accuracy to check for overfitting.\n",
    "y_pred_train = log_reg.predict(exog=X_train)\n",
    "# Convert predicted probabilities to binary class (0 or 1)\n",
    "y_pred_train = y_pred_train.apply(lambda x: 1 if x >= 0.5 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training-set accuracy score: {0:0.4f}'. format(accuracy_score(y_train, y_pred_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These two accuracies should be close if not overfitting has occured"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression test assumptions\n",
    "\n",
    "When the assumptions of logistic regression analysis are not met, problems such as biased coefficient estimates or very large standard errors for the logistic regression coefficients may lead to invalid statistical inferences.\n",
    "\n",
    "Assumption 1 - Appropriate outcome type (Must be categorical)\n",
    "\n",
    "Assumption 2 - Linearity of independent variables and log odds\n",
    "\n",
    "Assumption 3 - No strongly influential outliers\n",
    "\n",
    "Assumption 4 - Absence of multicollinearity\n",
    "\n",
    "Assumption 5 - Independence of observations\n",
    "\n",
    "Assumption 6 - Sufficiently large sample size\n",
    "\n",
    "Using: https://github.com/sandipanpaul21/Logistic-regression-in-python/blob/main/07_LR_Assumptions.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assumption 3:\n",
    "from scipy import stats\n",
    "\n",
    "# Get influence measures\n",
    "influence = log_reg.get_influence()\n",
    "\n",
    "# Obtain summary df of influence measures\n",
    "summ_df = influence.summary_frame()\n",
    "\n",
    "# Filter summary df to Cook distance\n",
    "diagnosis_df = summ_df.loc[:,['cooks_d']]\n",
    "\n",
    "# Append absolute standardized residual values\n",
    "diagnosis_df['std_resid'] = stats.zscore(log_reg.resid_pearson)\n",
    "diagnosis_df['std_resid'] = diagnosis_df.loc[:,'std_resid'].apply(lambda x: np.abs(x))\n",
    "\n",
    "# Sort by Cook's Distance\n",
    "diagnosis_df.sort_values(\"cooks_d\", ascending=False)\n",
    "diagnosis_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Cook's distance threshold\n",
    "cook_threshold = 4 / len(X)\n",
    "print(f\"Threshold for Cook Distance = {cook_threshold}\")\n",
    "\n",
    "# Plot influence measures (Cook's distance)\n",
    "fig = influence.plot_index(y_var=\"cooks\", threshold=cook_threshold)\n",
    "plt.axhline(y = cook_threshold, ls=\"--\", color='red')\n",
    "fig.tight_layout(pad=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find number of observations that exceed Cook's distance threshold\n",
    "outliers = diagnosis_df[diagnosis_df['cooks_d'] > cook_threshold]\n",
    "prop_outliers = round(100*(len(outliers) / len(X)),1)\n",
    "print(f'Proportion of data points that are highly influential = {prop_outliers}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Find number of observations which are BOTH outlier (std dev > 3) and highly influential\n",
    "extreme = diagnosis_df[(diagnosis_df['cooks_d'] > cook_threshold) & \n",
    "                       (diagnosis_df['std_resid'] > 3)]\n",
    "prop_extreme = round(100*(len(extreme) / len(X)),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Display top 5 most influential outliers\n",
    "extreme.sort_values(\"cooks_d\", ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It is important to note that for data points with relative high Cook's distances, it does not automatically mean that it should be immediately removed from the dataset.\n",
    "- It is essentially an indicator to highlight which data points are worth looking deeper into, to understand whether they are true anomalies or not\n",
    "- In practice, an assessment of “large” values is a judgement call based on experience and the particular set of data being analyzed.\n",
    "- In addition, based on our pre-defined threshold (4/N), only 5% (51/891) of the points are in the outlier zone, which is small as well. \n",
    "- The issue comes when there is a significant number of data points classified as outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assumption 4:\n",
    "# Use variance inflation factor to identify any significant multi-collinearity\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "def calc_vif(df):\n",
    "    vif = pd.DataFrame()\n",
    "    vif[\"variables\"] = df.columns\n",
    "    vif[\"VIF\"] = [variance_inflation_factor(df.values, i) for i in range(df.shape[1])]\n",
    "    return(vif)\n",
    "\n",
    "calc_vif(X) # If >=5 Severe multicollineairty present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assumption 5: Checking for autocorrelation\n",
    "\n",
    "from statsmodels.stats.stattools import durbin_watson\n",
    "\n",
    "#perform Durbin-Watson test\n",
    "durbin_watson(log_reg.resid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform Jarque-Bera test to test for normal errors\n",
    "stats.jarque_bera(log_reg.resid)\n",
    "# If errors arent normal used residual based bootstrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maybe test for heteroskedasticity"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
